# Copyright (C) 2020 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not
# use this file except in compliance with the License. You may obtain a copy of
# the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations under
# the License.

# Example for a parameterized Dataproc Workflow template that uses a managed cluster

labels:
  application: dataproc-workflow-spark-poc # Template labels are applied to Jobs and Managed Clusters
jobs:
- pysparkJob:
    jarFileUris:
    - gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar
    args:
    - input_table_parameter
    - output_table_parameter
    - temp_gcs_bucket_parameter
    mainPythonFileUri: main_python_file_parameter
  stepId: pyspark-demo
placement:
  managedCluster:
    clusterName: managed-spark-poc
    config:
      gceClusterConfig:
        zoneUri: '' # auto zone placement
      masterConfig:
        numInstances: 1
        machineTypeUri: n1-standard-4
        diskConfig:
          bootDiskSizeGb: 500
      workerConfig:
        numInstances: 2
        machineTypeUri: n1-standard-4
        diskConfig:
          bootDiskSizeGb: 500
      softwareConfig:
        imageVersion: 1.5-debian10
parameters:
- name: MAIN_PYTHON_FILE 
  description: Python script to run
  fields:
  - jobs['pyspark-demo'].pysparkJob.mainPythonFileUri
- name: INPUT_TABLE
  description: BigQuery input table
  fields:
  - jobs['pyspark-demo'].pysparkJob.args[0]
- name: OUTPUT_TABLE
  description: BigQuery output table
  fields:
  - jobs['pyspark-demo'].pysparkJob.args[1]
- name: TEMP_GCS_BUCKET
  description: Temp GCS bucket name
  fields:
  - jobs['pyspark-demo'].pysparkJob.args[2]
- name: CLUSTER_WORKERS_COUNT
  description: Number of primary worker nodes in the cluster
  fields:
    - placement.managedCluster.config.workerConfig.numInstances
  
